"""é›†ä¸­å¼é˜Ÿåˆ—ç®¡ç†å™¨
è´Ÿè´£ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ä»»åŠ¡é˜Ÿåˆ—çš„å¤„ç†è¯·æ±‚ï¼Œé¿å…å¹¶å‘å†²çª
"""

import threading
import time
from datetime import datetime, timedelta
from enum import Enum
from typing import Optional, Dict, Any
from flask import current_app
from app import db
from app.models.Task import Task
from app.models.TaskLog import TaskLog
from app.services.runninghub import RunningHubService
import logging

logger = logging.getLogger(__name__)

class TriggerSource(Enum):
    """è§¦å‘æºæšä¸¾"""
    USER_START = "user_start"
    TASK_COMPLETE = "task_complete"
    TASK_STOP = "task_stop"
    TIMEOUT_CHECK = "timeout_check"
    STATUS_MONITOR = "status_monitor"
    PENDING_CHECK = "pending_check"
    BACKGROUND = "background"

class CentralQueueManager:
    """é›†ä¸­å¼é˜Ÿåˆ—ç®¡ç†å™¨
    
    ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ä»»åŠ¡é˜Ÿåˆ—å¤„ç†è¯·æ±‚ï¼Œç¡®ä¿åŒæ—¶åªæœ‰ä¸€ä¸ªé˜Ÿåˆ—å¤„ç†æ“ä½œåœ¨æ‰§è¡Œ
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._initialized = False
            return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        if self._initialized:
            return
            
        self._processing_lock = threading.RLock()  # å¯é‡å…¥é”
        self._processing = False
        self._last_process_time = 0
        self._min_interval = 1  # æœ€å°å¤„ç†é—´éš”ï¼ˆç§’ï¼‰
        self._request_count = 0
        self._success_count = 0
        self._skip_count = 0
        
        # è¿œç¨‹çŠ¶æ€ç¼“å­˜ï¼ˆç®€å•TTLï¼Œæ— æŒ‡æ•°é€€é¿ï¼‰
        self._status_cache_value = None
        self._status_cache_time = 0
        
        self.runninghub_service = RunningHubService()
        self._initialized = True
        
        logger.info("Central Queue Manager initialized")
    
    def request_queue_processing(self, trigger_source: TriggerSource, reason: str, 
                               task_id: Optional[str] = None, force: bool = False) -> bool:
        """ç»Ÿä¸€çš„é˜Ÿåˆ—å¤„ç†è¯·æ±‚å…¥å£
        
        Args:
            trigger_source: è§¦å‘æº
            reason: è§¦å‘åŸå› 
            task_id: ç›¸å…³ä»»åŠ¡IDï¼ˆå¯é€‰ï¼‰
            force: æ˜¯å¦å¼ºåˆ¶å¤„ç†ï¼Œå¿½ç•¥é—´éš”é™åˆ¶
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå¤„ç†äº†é˜Ÿåˆ—
        """
        self._request_count += 1
        
        with self._processing_lock:
            # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†
            if self._processing:
                logger.debug(f"Queue already processing, ignoring request from {trigger_source.value}: {reason}")
                self._skip_count += 1
                return False
            
            # æ£€æŸ¥å¤„ç†é—´éš”ï¼ˆé™¤éå¼ºåˆ¶å¤„ç†ï¼‰
            if not force:
                current_time = time.time()
                if current_time - self._last_process_time < self._min_interval:
                    logger.debug(f"Too frequent request from {trigger_source.value}, skipping: {reason}")
                    self._skip_count += 1
                    return False
            
            # å¼€å§‹å¤„ç†
            self._processing = True
            self._last_process_time = time.time()
            
            try:
                logger.info(f"Processing queue request from {trigger_source.value}: {reason}" + 
                          (f" (task: {task_id})" if task_id else ""))
                
                success = self._process_queue_internal(trigger_source, reason, task_id)
                
                if success:
                    self._success_count += 1
                    logger.info(f"Queue processing completed successfully from {trigger_source.value}")
                else:
                    logger.debug(f"Queue processing completed with no action from {trigger_source.value}")
                
                return success
                
            except Exception as e:
                logger.error(f"Error in queue processing from {trigger_source.value}: {e}", exc_info=True)
                return False
            finally:
                self._processing = False
    
    def _process_queue_internal(self, trigger_source: TriggerSource, reason: str, 
                              task_id: Optional[str] = None) -> bool:
        """å†…éƒ¨é˜Ÿåˆ—å¤„ç†é€»è¾‘
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸå¯åŠ¨äº†æ–°ä»»åŠ¡
        """
        try:
            # åœ¨ä»»ä½•è¿œç¨‹çŠ¶æ€æŸ¥è¯¢å‰ï¼Œå…ˆç¡®è®¤æ˜¯å¦å­˜åœ¨å¾…å¯åŠ¨ä»»åŠ¡
            if not self._has_pending_tasks():
                logger.debug("No pending tasks in queue, skipping remote status check")
                return False
            
            # 1. æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ‰§è¡Œæ§½ä½
            if not self._can_start_task():
                # ä½¿ç”¨ç¼“å­˜çš„è¿œç¨‹çŠ¶æ€è¿›è¡Œæ—¥å¿—è¾“å‡ºï¼Œé¿å…ä¸å¿…è¦çš„è¿œç¨‹è°ƒç”¨
                current_tasks = self._get_current_tasks_cached()
                if current_tasks is not None:
                    max_concurrent = current_app.config.get('MAX_CONCURRENT_TASKS', 1)
                    logger.debug(f"RunningHub status: {current_tasks}/{max_concurrent} tasks, waiting for completion")
                else:
                    logger.debug("No available slots for new tasks (using local fallback or unknown remote status)")
                return False
            
            # 2. è·å–ä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„ä»»åŠ¡
            next_task = self._get_next_pending_task()
            if not next_task:
                logger.debug("No pending tasks in queue")
                return False
            
            logger.info(f"Processing task {next_task.task_id} from queue (triggered by {trigger_source.value})")
            
            # 3. åœ¨æäº¤å‰å†æ¬¡æ£€æŸ¥RunningHubçŠ¶æ€ï¼Œé¿å…å¹¶å‘é—®é¢˜
            if not self._can_start_task():
                logger.debug(f"RunningHub status changed, cannot start task {next_task.task_id}")
                return False
            
            # 4. æäº¤ä»»åŠ¡åˆ°RunningHub
            return self._submit_task_to_runninghub(next_task, trigger_source)
            
        except Exception as e:
            logger.error(f"Error in internal queue processing: {e}", exc_info=True)
            return False
    
    def _has_pending_tasks(self) -> bool:
        """æ˜¯å¦å­˜åœ¨å¾…å¯åŠ¨ä»»åŠ¡ï¼ˆæœ¬åœ°çŸ­è·¯ï¼‰"""
        try:
            return Task.query.filter_by(status='PENDING').count() > 0
        except Exception as e:
            logger.error(f"Error checking pending tasks: {e}")
            # å‡ºé”™æ—¶ä¸é˜»å¡è°ƒåº¦ï¼Œè¿”å›Trueä»¥ç»§ç»­åç»­é€»è¾‘
            return True
    
    def _get_current_tasks_cached(self, force_refresh: bool = False) -> Optional[int]:
        """å¸¦TTLçš„è¿œç¨‹ä»»åŠ¡æ•°è·å–ï¼ˆç®€å•ç¼“å­˜ï¼‰"""
        try:
            ttl = 30
            try:
                ttl = current_app.config.get('RUNNINGHUB_STATUS_TTL', 30)
            except Exception:
                pass
            now = time.time()
            if (not force_refresh) and self._status_cache_value is not None and (now - self._status_cache_time) < ttl:
                return self._status_cache_value
            
            current_tasks = self.runninghub_service.check_account_status()
            if current_tasks is not None:
                self._status_cache_value = current_tasks
                self._status_cache_time = now
                return current_tasks
            # ä¸ç¼“å­˜Noneï¼Œä»¥ä¾¿ä¸‹æ¬¡æœ‰æœºä¼šé‡æ–°è¯·æ±‚
            return None
        except Exception as e:
            logger.error(f"Error getting cached RunningHub status: {e}")
            return None
    
    def _can_start_task(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡"""
        try:
            # æœ¬åœ°å¾…å¯åŠ¨ä»»åŠ¡çŸ­è·¯ï¼šæ— å¾…å¯åŠ¨ä»»åŠ¡åˆ™ä¸éœ€æŸ¥è¯¢è¿œç¨‹çŠ¶æ€
            if not self._has_pending_tasks():
                logger.debug("No pending tasks, skip remote status check")
                return False
            
            # å…ˆå°è¯•ä½¿ç”¨ç¼“å­˜çš„è¿œç¨‹çŠ¶æ€
            current_tasks = self._get_current_tasks_cached()
            
            if current_tasks is not None:
                # æˆåŠŸè·å–RunningHubçŠ¶æ€
                max_concurrent = current_app.config.get('MAX_CONCURRENT_TASKS', 1)
                can_start = current_tasks < max_concurrent
                logger.debug(f"RunningHub status: {current_tasks}/{max_concurrent} tasks, can_start: {can_start}")
                # é‡ç½®è¿æ¥å¤±è´¥è®¡æ•°å™¨
                if not hasattr(self, '_runninghub_fail_count'):
                    self._runninghub_fail_count = 0
                self._runninghub_fail_count = 0
                return can_start
            else:
                # æ— æ³•è·å–RunningHubçŠ¶æ€ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®åº“ä½œä¸ºå¤‡é€‰
                if not hasattr(self, '_runninghub_fail_count'):
                    self._runninghub_fail_count = 0
                self._runninghub_fail_count += 1
                
                if self._runninghub_fail_count == 1 or self._runninghub_fail_count % 10 == 0:
                    logger.warning(f"Cannot get RunningHub status (attempt {self._runninghub_fail_count}), using local database as fallback")
                
                running_count = Task.query.filter(Task.status.in_(['QUEUED', 'RUNNING'])).count()
                max_concurrent = current_app.config.get('MAX_CONCURRENT_TASKS', 1)
                can_start = running_count < max_concurrent
                logger.debug(f"Local database status: {running_count}/{max_concurrent} tasks, can_start: {can_start}")
                return can_start
                
        except Exception as e:
            logger.error(f"Error checking if can start task: {e}")
            # å‡ºé”™æ—¶å…è®¸å¯åŠ¨ï¼Œé¿å…ç³»ç»Ÿå¡æ­»
            return True
    
    def _get_next_pending_task(self) -> Optional[Task]:
        """è·å–ä¸‹ä¸€ä¸ªå¾…å¤„ç†çš„ä»»åŠ¡"""
        try:
            return Task.query.filter_by(status='PENDING').order_by(Task.created_at.asc()).first()
        except Exception as e:
            logger.error(f"Error getting next pending task: {e}")
            return None
    
    def _submit_task_to_runninghub(self, task: Task, trigger_source: TriggerSource) -> bool:
        """æäº¤ä»»åŠ¡åˆ°RunningHub
        
        Args:
            task: è¦æäº¤çš„ä»»åŠ¡
            trigger_source: è§¦å‘æº
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæäº¤
        """
        try:
            # è®°å½•å¼€å§‹æäº¤ä»»åŠ¡çš„æ—¥å¿—
            start_log = TaskLog(
                task_id=task.task_id,
                message=f"ğŸš€ å¼€å§‹æäº¤ä»»åŠ¡åˆ°RunningHub (è§¦å‘æº: {trigger_source.value})..."
            )
            db.session.add(start_log)
            db.session.commit()
            
            # è°ƒç”¨åŸæœ‰çš„æäº¤é€»è¾‘
            from app.services.task_queue_service import TaskQueueService
            queue_service = TaskQueueService()
            success, runninghub_task_id, error_msg = queue_service.submit_task_to_runninghub(task)
            
            if success:
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task.status = 'QUEUED'
                task.runninghub_task_id = runninghub_task_id
                task.started_at = datetime.utcnow()
                db.session.commit()
                
                logger.info(f"Task {task.task_id} submitted to RunningHub with ID: {runninghub_task_id}")
                
                # è®°å½•æˆåŠŸæäº¤çš„æ—¥å¿—
                success_log = TaskLog(
                    task_id=task.task_id,
                    message=f"âœ… ä»»åŠ¡å·²æˆåŠŸæäº¤åˆ°RunningHub (ID: {runninghub_task_id}, è§¦å‘æº: {trigger_source.value})"
                )
                db.session.add(success_log)
                db.session.commit()
                
                return True
            else:
                # å¤„ç†æäº¤å¤±è´¥çš„æƒ…å†µ
                if error_msg and 'TASK_QUEUE_MAXED' in error_msg:
                    # é˜Ÿåˆ—æ»¡æ—¶ï¼Œä»»åŠ¡ä¿æŒPENDINGçŠ¶æ€
                    logger.info(f"RunningHub queue is full, task {task.task_id} remains in PENDING status")
                    
                    # è®°å½•é˜Ÿåˆ—æ»¡çš„æ—¥å¿—ï¼ˆé¿å…é‡å¤è®°å½•ï¼‰
                    existing_queue_log = TaskLog.query.filter_by(
                        task_id=task.task_id
                    ).filter(
                        TaskLog.message.like('%é˜Ÿåˆ—å·²æ»¡%')
                    ).first()
                    
                    if not existing_queue_log:
                        queue_log = TaskLog(
                            task_id=task.task_id,
                            message=f"â³ RunningHubé˜Ÿåˆ—å·²æ»¡ï¼Œç­‰å¾…ç©ºé—²æ§½ä½... (è§¦å‘æº: {trigger_source.value})"
                        )
                        db.session.add(queue_log)
                        db.session.commit()
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œæ ‡è®°ä»»åŠ¡å¤±è´¥
                    task.status = 'FAILED'
                    if hasattr(task, 'completed_at'):
                        task.completed_at = datetime.utcnow()
                    db.session.commit()
                    
                    error_log = TaskLog(
                        task_id=task.task_id,
                        message=f"âŒ ä»»åŠ¡æäº¤å¤±è´¥: {error_msg or 'æœªçŸ¥é”™è¯¯'} (è§¦å‘æº: {trigger_source.value})"
                    )
                    db.session.add(error_log)
                    db.session.commit()
                    
                    logger.error(f"Failed to submit task {task.task_id}: {error_msg}")
                
                return False
                
        except Exception as e:
            logger.error(f"Error submitting task {task.task_id} to RunningHub: {e}", exc_info=True)
            
            # è®°å½•å¼‚å¸¸æ—¥å¿—
            try:
                error_log = TaskLog(
                    task_id=task.task_id,
                    message=f"âŒ ä»»åŠ¡æäº¤å¼‚å¸¸: {str(e)} (è§¦å‘æº: {trigger_source.value})"
                )
                db.session.add(error_log)
                db.session.commit()
            except:
                pass  # é¿å…æ—¥å¿—è®°å½•å¤±è´¥å½±å“ä¸»æµç¨‹
            
            return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯"""
        with self._processing_lock:
            return {
                'request_count': self._request_count,
                'success_count': self._success_count,
                'skip_count': self._skip_count,
                'is_processing': self._processing,
                'last_process_time': self._last_process_time,
                'success_rate': self._success_count / max(self._request_count, 1) * 100
            }
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        with self._processing_lock:
            self._request_count = 0
            self._success_count = 0
            self._skip_count = 0
            logger.info("Central Queue Manager statistics reset")

# å…¨å±€ä¸­å¤®é˜Ÿåˆ—ç®¡ç†å™¨å®ä¾‹
central_queue_manager = CentralQueueManager()