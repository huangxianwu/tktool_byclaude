"""æ•…éšœæ¢å¤æœåŠ¡
è´Ÿè´£ç³»ç»Ÿé‡å¯åçš„ä»»åŠ¡çŠ¶æ€åŒæ­¥å’Œæ•°æ®å®Œæ•´æ€§æ¢å¤
"""
import logging
import os
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from flask import current_app
from app import db
from app.models.Task import Task
from app.models.TaskLog import TaskLog
from app.models.TaskOutput import TaskOutput
from app.services.runninghub import RunningHubService
from app.services.file_manager import FileManager

logger = logging.getLogger(__name__)

class RecoveryService:
    """æ•…éšœæ¢å¤æœåŠ¡ - å¤„ç†ç³»ç»Ÿé‡å¯åçš„ä»»åŠ¡çŠ¶æ€åŒæ­¥"""
    
    def __init__(self):
        self.runninghub_service = RunningHubService()
        self.file_manager = FileManager()
        self.recovery_stats = {
            'total_tasks': 0,
            'synced_tasks': 0,
            'failed_tasks': 0,
            'completed_tasks': 0,
            'running_tasks': 0,
            'missing_tasks': 0,
            'start_time': None,
            'end_time': None
        }
    
    def perform_recovery(self, delay_seconds: int = 3) -> Dict[str, Any]:
        """æ‰§è¡Œæ•…éšœæ¢å¤
        
        Args:
            delay_seconds: å»¶è¿Ÿå¯åŠ¨ç§’æ•°ï¼Œç¡®ä¿æ‰€æœ‰æœåŠ¡å°±ç»ª
            
        Returns:
            æ¢å¤ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info(f"Starting system recovery in {delay_seconds} seconds...")
        time.sleep(delay_seconds)
        
        self.recovery_stats['start_time'] = datetime.utcnow()
        
        try:
            # 1. è¯†åˆ«éœ€è¦åŒæ­¥çš„ä»»åŠ¡
            tasks_to_sync = self._identify_tasks_to_sync()
            self.recovery_stats['total_tasks'] = len(tasks_to_sync)
            
            if not tasks_to_sync:
                logger.info("No tasks need recovery")
                self.recovery_stats['end_time'] = datetime.utcnow()
                return self.recovery_stats
            
            logger.info(f"Found {len(tasks_to_sync)} tasks that need recovery")
            
            # 2. æ‰¹é‡æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
            status_results = self._batch_query_task_status(tasks_to_sync)
            
            # 3. åŒæ­¥ä»»åŠ¡çŠ¶æ€
            self._sync_task_status(tasks_to_sync, status_results)
            
            # 4. æ¢å¤æ•°æ®å®Œæ•´æ€§
            self._restore_data_integrity(tasks_to_sync, status_results)
            
            # 5. æ¢å¤è¾“å‡ºæ–‡ä»¶å®Œæ•´æ€§
            self._restore_output_files_integrity()
            
            # 6. é‡å»ºå¹¶å‘æ§åˆ¶
            self._rebuild_concurrency_control()
            
            self.recovery_stats['end_time'] = datetime.utcnow()
            duration = (self.recovery_stats['end_time'] - self.recovery_stats['start_time']).total_seconds()
            
            logger.info(f"Recovery completed in {duration:.2f} seconds")
            logger.info(f"Recovery stats: {self.recovery_stats}")
            
            return self.recovery_stats
            
        except Exception as e:
            logger.error(f"Recovery failed: {e}")
            self.recovery_stats['end_time'] = datetime.utcnow()
            raise
    
    def _identify_tasks_to_sync(self) -> List[Task]:
        """è¯†åˆ«éœ€è¦åŒæ­¥çš„ä»»åŠ¡"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰æœªå®Œæˆä¸”æœ‰runninghub_task_idçš„ä»»åŠ¡
            tasks = Task.query.filter(
                Task.status.in_(['PENDING', 'QUEUED', 'RUNNING']),
                Task.runninghub_task_id.isnot(None),
                Task.runninghub_task_id != ''
            ).all()
            
            logger.info(f"Found {len(tasks)} tasks with incomplete status")
            
            # è®°å½•éœ€è¦åŒæ­¥çš„ä»»åŠ¡
            for task in tasks:
                logger.info(f"Task {task.task_id} (RunningHub: {task.runninghub_task_id}) - Status: {task.status}")
            
            return tasks
            
        except Exception as e:
            logger.error(f"Failed to identify tasks to sync: {e}")
            return []
    
    def _batch_query_task_status(self, tasks: List[Task]) -> Dict[str, Dict[str, Any]]:
        """æ‰¹é‡æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
        status_results = {}
        
        logger.info(f"Querying status for {len(tasks)} tasks...")
        
        for task in tasks:
            try:
                # æŸ¥è¯¢è¿œç¨‹ä»»åŠ¡çŠ¶æ€
                status_info = self.runninghub_service.get_task_status(task.runninghub_task_id)
                
                if status_info and 'status' in status_info:
                    remote_status = status_info['status'].upper()
                    status_results[task.task_id] = {
                        'exists': True,
                        'status': remote_status,
                        'runninghub_task_id': task.runninghub_task_id
                    }
                    logger.info(f"Task {task.task_id}: Remote status = {remote_status}")
                else:
                    # ä»»åŠ¡ä¸å­˜åœ¨æˆ–æŸ¥è¯¢å¤±è´¥
                    status_results[task.task_id] = {
                        'exists': False,
                        'status': None,
                        'runninghub_task_id': task.runninghub_task_id
                    }
                    logger.warning(f"Task {task.task_id}: Not found on RunningHub")
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.1)
                
            except Exception as e:
                logger.error(f"Failed to query status for task {task.task_id}: {e}")
                status_results[task.task_id] = {
                    'exists': False,
                    'status': None,
                    'error': str(e),
                    'runninghub_task_id': task.runninghub_task_id
                }
        
        return status_results
    
    def _sync_task_status(self, tasks: List[Task], status_results: Dict[str, Dict[str, Any]]):
        """åŒæ­¥ä»»åŠ¡çŠ¶æ€"""
        for task in tasks:
            try:
                result = status_results.get(task.task_id, {})
                
                if result.get('exists', False):
                    # è¿œç¨‹ä»»åŠ¡å­˜åœ¨ï¼ŒåŒæ­¥çŠ¶æ€
                    remote_status = result['status']
                    self._sync_existing_task(task, remote_status)
                else:
                    # è¿œç¨‹ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå¤„ç†ä¸¢å¤±ä»»åŠ¡
                    self._handle_missing_task(task)
                    
            except Exception as e:
                logger.error(f"Failed to sync task {task.task_id}: {e}")
                self.recovery_stats['failed_tasks'] += 1
    
    def _sync_existing_task(self, task: Task, remote_status: str):
        """åŒæ­¥å­˜åœ¨çš„ä»»åŠ¡"""
        old_status = task.status
        
        # æ˜ å°„RunningHubçŠ¶æ€åˆ°æœ¬åœ°çŠ¶æ€
        status_mapping = {
            'QUEUE': 'QUEUED',
            'QUEUED': 'QUEUED', 
            'RUNNING': 'RUNNING',
            'SUCCESS': 'SUCCESS',
            'FAILED': 'FAILED'
        }
        
        new_status = status_mapping.get(remote_status, remote_status)
        
        if old_status != new_status:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = new_status
            
            # è®¾ç½®å®Œæˆæ—¶é—´
            if new_status in ['SUCCESS', 'FAILED'] and not task.completed_at:
                task.completed_at = datetime.utcnow()
            
            # é‡æ–°è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆå¯¹äºè¿è¡Œä¸­çš„ä»»åŠ¡ï¼‰
            if new_status == 'RUNNING':
                timeout_minutes = current_app.config.get('TASK_TIMEOUT_MINUTES', 600)
                task.timeout_at = datetime.utcnow() + timedelta(minutes=timeout_minutes)
            
            db.session.commit()
            
            # è®°å½•æ¢å¤æ—¥å¿—
            recovery_log = TaskLog(
                task_id=task.task_id,
                message=f"ğŸ”„ ç³»ç»Ÿæ¢å¤ï¼šçŠ¶æ€å·²åŒæ­¥ {old_status} â†’ {new_status}"
            )
            db.session.add(recovery_log)
            db.session.commit()
            
            logger.info(f"Task {task.task_id} status synced: {old_status} â†’ {new_status}")
            
            # æ›´æ–°ç»Ÿè®¡
            if new_status in ['SUCCESS', 'FAILED']:
                self.recovery_stats['completed_tasks'] += 1
            elif new_status in ['QUEUED', 'RUNNING']:
                self.recovery_stats['running_tasks'] += 1
        
        self.recovery_stats['synced_tasks'] += 1
    
    def _handle_missing_task(self, task: Task):
        """å¤„ç†ä¸¢å¤±çš„ä»»åŠ¡"""
        # æ£€æŸ¥ä»»åŠ¡å¯åŠ¨æ—¶é—´
        if task.started_at:
            time_since_start = datetime.utcnow() - task.started_at
            
            # å¦‚æœè¶…è¿‡2å°æ—¶ï¼Œæ ‡è®°ä¸ºå¤±è´¥
            if time_since_start > timedelta(hours=2):
                old_status = task.status
                task.status = 'FAILED'
                task.completed_at = datetime.utcnow()
                
                db.session.commit()
                
                # è®°å½•å¤±è´¥æ—¥å¿—
                failure_log = TaskLog(
                    task_id=task.task_id,
                    message=f"âŒ ç³»ç»Ÿæ¢å¤ï¼šä»»åŠ¡åœ¨RunningHubä¸Šä¸å­˜åœ¨ï¼Œå·²æ ‡è®°ä¸ºå¤±è´¥ (è¿è¡Œæ—¶é—´: {time_since_start})"
                )
                db.session.add(failure_log)
                db.session.commit()
                
                logger.warning(f"Task {task.task_id} marked as FAILED (missing on RunningHub, runtime: {time_since_start})")
                self.recovery_stats['completed_tasks'] += 1
            else:
                # æ—¶é—´è¾ƒçŸ­ï¼Œé‡ç½®ä¸ºREADYçŠ¶æ€
                old_status = task.status
                task.status = 'READY'
                task.runninghub_task_id = None
                task.started_at = None
                
                db.session.commit()
                
                # è®°å½•é‡ç½®æ—¥å¿—
                reset_log = TaskLog(
                    task_id=task.task_id,
                    message=f"ğŸ”„ ç³»ç»Ÿæ¢å¤ï¼šä»»åŠ¡é‡ç½®ä¸ºREADYçŠ¶æ€ï¼Œå¯é‡æ–°æ‰§è¡Œ"
                )
                db.session.add(reset_log)
                db.session.commit()
                
                logger.info(f"Task {task.task_id} reset to READY (missing on RunningHub, runtime: {time_since_start})")
        else:
            # æ²¡æœ‰å¯åŠ¨æ—¶é—´ï¼Œç›´æ¥é‡ç½®ä¸ºREADY
            task.status = 'READY'
            task.runninghub_task_id = None
            
            db.session.commit()
            
            reset_log = TaskLog(
                task_id=task.task_id,
                message=f"ğŸ”„ ç³»ç»Ÿæ¢å¤ï¼šä»»åŠ¡é‡ç½®ä¸ºREADYçŠ¶æ€"
            )
            db.session.add(reset_log)
            db.session.commit()
            
            logger.info(f"Task {task.task_id} reset to READY (no start time)")
        
        self.recovery_stats['missing_tasks'] += 1
    
    def _restore_data_integrity(self, tasks: List[Task], status_results: Dict[str, Dict[str, Any]]):
        """æ¢å¤æ•°æ®å®Œæ•´æ€§"""
        logger.info("Starting data integrity restoration...")
        
        for task in tasks:
            try:
                result = status_results.get(task.task_id, {})
                
                # åªå¤„ç†å·²å®Œæˆçš„ä»»åŠ¡
                if result.get('exists', False) and task.status == 'SUCCESS':
                    self._restore_task_outputs(task)
                    
            except Exception as e:
                logger.error(f"Failed to restore data integrity for task {task.task_id}: {e}")
    
    def _restore_task_outputs(self, task: Task):
        """æ¢å¤ä»»åŠ¡è¾“å‡ºæ–‡ä»¶"""
        try:
            # è·å–è¿œç¨‹è¾“å‡ºåˆ—è¡¨
            remote_outputs = self.runninghub_service.get_task_outputs(task.runninghub_task_id)
            
            if not remote_outputs:
                return
            
            # æ£€æŸ¥æœ¬åœ°è¾“å‡ºè®°å½•
            local_outputs = TaskOutput.query.filter_by(task_id=task.task_id).all()
            local_output_names = {output.name for output in local_outputs}
            
            # ä¸‹è½½ç¼ºå¤±çš„è¾“å‡ºæ–‡ä»¶
            for remote_output in remote_outputs:
                output_name = remote_output['name']
                
                if output_name not in local_output_names:
                    logger.info(f"Downloading missing output: {output_name} for task {task.task_id}")
                    
                    # ä¸‹è½½æ–‡ä»¶
                    file_content = self.runninghub_service.download_output_file(
                        task.runninghub_task_id, output_name
                    )
                    
                    if file_content:
                        # ä¿å­˜æ–‡ä»¶
                        file_path = self.file_manager.save_output_file(
                            task.task_id, output_name, file_content
                        )
                        
                        # åˆ›å»ºè¾“å‡ºè®°å½•
                        task_output = TaskOutput(
                            task_id=task.task_id,
                            name=output_name,
                            file_path=file_path,
                            file_type=remote_output.get('type', ''),
                            node_id=remote_output.get('node_id', '')
                        )
                        db.session.add(task_output)
                        
                        logger.info(f"Restored output file: {output_name}")
            
            db.session.commit()
            
        except Exception as e:
            logger.error(f"Failed to restore outputs for task {task.task_id}: {e}")
    
    def _rebuild_concurrency_control(self):
        """é‡å»ºå¹¶å‘æ§åˆ¶"""
        try:
            # ç»Ÿè®¡å½“å‰è¿è¡Œä¸­çš„ä»»åŠ¡æ•°é‡
            running_count = Task.query.filter(
                Task.status.in_(['QUEUED', 'RUNNING'])
            ).count()
            
            logger.info(f"Current running tasks: {running_count}")
            
            # è¿™é‡Œå¯ä»¥é‡ç½®å¹¶å‘æ§åˆ¶ç›¸å…³çš„çŠ¶æ€
            # å…·ä½“å®ç°å–å†³äºå¹¶å‘æ§åˆ¶çš„æœºåˆ¶
            
        except Exception as e:
            logger.error(f"Failed to rebuild concurrency control: {e}")
    
    def get_recovery_stats(self) -> Dict[str, Any]:
        """è·å–æ¢å¤ç»Ÿè®¡ä¿¡æ¯"""
        return self.recovery_stats.copy()
    
    def manual_sync_task(self, task_id: str) -> bool:
        """æ‰‹åŠ¨åŒæ­¥å•ä¸ªä»»åŠ¡"""
        try:
            task = Task.query.filter_by(task_id=task_id).first()
            if not task or not task.runninghub_task_id:
                return False
            
            # æŸ¥è¯¢è¿œç¨‹çŠ¶æ€
            status_info = self.runninghub_service.get_task_status(task.runninghub_task_id)
            
            if status_info and 'status' in status_info:
                remote_status = status_info['status'].upper()
                self._sync_existing_task(task, remote_status)
                
                # å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œæ¢å¤è¾“å‡ºæ–‡ä»¶
                if task.status == 'SUCCESS':
                    self._restore_task_outputs(task)
                
                return True
            else:
                self._handle_missing_task(task)
                return True
                
        except Exception as e:
            logger.error(f"Failed to manually sync task {task_id}: {e}")
            return False
    
    def _restore_output_files_integrity(self):
        """æ¢å¤è¾“å‡ºæ–‡ä»¶å®Œæ•´æ€§ - æ£€æŸ¥æ‰€æœ‰SUCCESSä»»åŠ¡çš„æ–‡ä»¶å®Œæ•´æ€§"""
        try:
            logger.info("Starting output files integrity restoration...")
            
            # æŸ¥æ‰¾æ‰€æœ‰SUCCESSçŠ¶æ€çš„ä»»åŠ¡
            success_tasks = Task.query.filter_by(status='SUCCESS').all()
            
            if not success_tasks:
                logger.info("No SUCCESS tasks found for file integrity check")
                return
            
            logger.info(f"Found {len(success_tasks)} SUCCESS tasks to check")
            
            restored_count = 0
            failed_count = 0
            
            for task in success_tasks:
                try:
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æœ‰æœ¬åœ°è¾“å‡ºæ–‡ä»¶
                    local_outputs = TaskOutput.query.filter_by(task_id=task.task_id).all()
                    
                    if not local_outputs:
                        # æ²¡æœ‰æœ¬åœ°æ–‡ä»¶è®°å½•ï¼Œå°è¯•æ¢å¤
                        logger.info(f"Task {task.task_id} has no local output files, attempting recovery...")
                        
                        if self._restore_task_outputs(task):
                            restored_count += 1
                            logger.info(f"Successfully restored outputs for task {task.task_id}")
                        else:
                            failed_count += 1
                            logger.warning(f"Failed to restore outputs for task {task.task_id}")
                    else:
                        # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        missing_files = []
                        for output in local_outputs:
                            if not os.path.exists(output.local_path):
                                missing_files.append(output)
                        
                        if missing_files:
                            logger.info(f"Task {task.task_id} has {len(missing_files)} missing local files, attempting recovery...")
                            
                            # åˆ é™¤ç¼ºå¤±æ–‡ä»¶çš„æ•°æ®åº“è®°å½•
                            for missing_output in missing_files:
                                db.session.delete(missing_output)
                            db.session.commit()
                            
                            # é‡æ–°ä¸‹è½½æ–‡ä»¶
                            if self._restore_task_outputs(task):
                                restored_count += 1
                                logger.info(f"Successfully restored missing files for task {task.task_id}")
                            else:
                                failed_count += 1
                                logger.warning(f"Failed to restore missing files for task {task.task_id}")
                
                except Exception as e:
                    logger.error(f"Error checking task {task.task_id}: {e}")
                    failed_count += 1
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.1)
            
            logger.info(f"Output files integrity restoration completed: {restored_count} restored, {failed_count} failed")
            
        except Exception as e:
            logger.error(f"Failed to restore output files integrity: {e}")
    
    def _restore_task_outputs(self, task: Task) -> bool:
        """æ¢å¤å•ä¸ªä»»åŠ¡çš„è¾“å‡ºæ–‡ä»¶"""
        try:
            if not task.runninghub_task_id:
                logger.warning(f"Task {task.task_id} has no RunningHub task ID")
                return False
            
            # ä»RunningHubè·å–è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            remote_outputs = self.runninghub_service.get_task_outputs(task.runninghub_task_id)
            
            if not remote_outputs:
                logger.info(f"No remote outputs found for task {task.task_id}")
                return True  # æ²¡æœ‰è¾“å‡ºæ–‡ä»¶ä¹Ÿç®—æˆåŠŸ
            
            # ä½¿ç”¨FileManagerä¸‹è½½æ–‡ä»¶
            formatted_outputs = []
            for i, output in enumerate(remote_outputs):
                file_url = output.get('url', '')
                file_name = output.get('name', 'output.file')
                file_extension = file_name.split('.')[-1].lower() if '.' in file_name else 'png'
                
                formatted_outputs.append({
                    'fileUrl': file_url,
                    'fileType': file_extension,
                    'nodeId': f'node_{i}'
                })
            
            # ä¸‹è½½å¹¶ä¿å­˜æ–‡ä»¶
            saved_files = self.file_manager.download_and_save_outputs(task.task_id, formatted_outputs)
            
            if saved_files:
                logger.info(f"Successfully downloaded {len(saved_files)} files for task {task.task_id}")
                return True
            else:
                logger.warning(f"No files were downloaded for task {task.task_id}")
                return False
                
        except Exception as e:
            logger.error(f"Failed to restore outputs for task {task.task_id}: {e}")
            return False
    
    def batch_restore_files(self, task_ids: List[str] = None) -> Dict[str, Any]:
        """æ‰¹é‡æ¢å¤æ–‡ä»¶ - å¯æŒ‡å®šä»»åŠ¡IDåˆ—è¡¨æˆ–æ¢å¤æ‰€æœ‰SUCCESSä»»åŠ¡"""
        try:
            if task_ids:
                # æ¢å¤æŒ‡å®šä»»åŠ¡
                tasks = Task.query.filter(Task.task_id.in_(task_ids), Task.status == 'SUCCESS').all()
            else:
                # æ¢å¤æ‰€æœ‰SUCCESSä»»åŠ¡
                tasks = Task.query.filter_by(status='SUCCESS').all()
            
            result = {
                'total_tasks': len(tasks),
                'restored_tasks': 0,
                'failed_tasks': 0,
                'start_time': datetime.utcnow().isoformat(),
                'details': []
            }
            
            for task in tasks:
                task_result = {
                    'task_id': task.task_id,
                    'status': 'success' if self._restore_task_outputs(task) else 'failed'
                }
                
                if task_result['status'] == 'success':
                    result['restored_tasks'] += 1
                else:
                    result['failed_tasks'] += 1
                
                result['details'].append(task_result)
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.1)
            
            result['end_time'] = datetime.utcnow().isoformat()
            
            logger.info(f"Batch file restoration completed: {result['restored_tasks']}/{result['total_tasks']} tasks restored")
            
            return result
            
        except Exception as e:
            logger.error(f"Batch file restoration failed: {e}")
            return {
                'error': str(e),
                'total_tasks': 0,
                'restored_tasks': 0,
                'failed_tasks': 0
            }

# å…¨å±€æ¢å¤æœåŠ¡å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
recovery_service = None

def get_recovery_service():
    """è·å–æ¢å¤æœåŠ¡å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global recovery_service
    if recovery_service is None:
        recovery_service = RecoveryService()
    return recovery_service