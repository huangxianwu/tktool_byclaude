"""
ä»»åŠ¡çŠ¶æ€ç›‘æ§æœåŠ¡
è´Ÿè´£ç›‘æ§RunningHubä»»åŠ¡çŠ¶æ€å¹¶æ›´æ–°æœ¬åœ°æ•°æ®åº“
"""
from datetime import datetime, timedelta
from flask import current_app
from app import db
from app.models.Task import Task
from app.models.TaskLog import TaskLog
from app.models.TaskOutput import TaskOutput
from app.services.runninghub import RunningHubService
from app.services.central_queue_manager import central_queue_manager, TriggerSource
from app.utils.timezone_helper import now_utc
import logging
import threading
import time

logger = logging.getLogger(__name__)

class TaskStatusService:
    def __init__(self):
        self.runninghub_service = RunningHubService()
        self.is_monitoring = False
        self.monitor_thread = None
        self.app = None
    
    def update_task_status(self, task_id):
        """æ›´æ–°å•ä¸ªä»»åŠ¡çš„çŠ¶æ€"""
        from app.models.TaskLog import TaskLog
        
        task = Task.query.get(task_id)
        if not task or not task.runninghub_task_id:
            return False
        
        # è®°å½•çŠ¶æ€æ£€æŸ¥å¼€å§‹
        check_log = TaskLog(
            task_id=task_id,
            message=f"ğŸ” æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ (è¿œç¨‹ID: {task.runninghub_task_id})"
        )
        db.session.add(check_log)
        db.session.commit()
        
        try:
            # ä»RunningHubè·å–ä»»åŠ¡çŠ¶æ€
            api_log = TaskLog(
                task_id=task_id,
                message="ğŸ“¡ ä»RunningHubè·å–ä»»åŠ¡çŠ¶æ€"
            )
            db.session.add(api_log)
            db.session.commit()
            
            status_info = self.runninghub_service.get_task_status(task.runninghub_task_id)
            
            if status_info:
                old_status = task.status
                new_status = self.map_runninghub_status(status_info.get('status', ''))
                
                status_log = TaskLog(
                    task_id=task_id,
                    message=f"ğŸ“Š è·å–åˆ°çŠ¶æ€ä¿¡æ¯: {status_info.get('status', 'unknown')} -> {new_status}"
                )
                db.session.add(status_log)
                db.session.commit()
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                if new_status and new_status != old_status:
                    task.status = new_status
                    
                    # å¦‚æœä»»åŠ¡çŠ¶æ€å˜æ›´ä¸ºRUNNINGï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
                    if new_status == 'RUNNING' and hasattr(task, 'timeout_at'):
                        timeout_minutes = current_app.config.get('TASK_TIMEOUT_MINUTES', 600)
                        task.timeout_at = datetime.utcnow() + timedelta(minutes=timeout_minutes)
                    
                    # å¦‚æœä»»åŠ¡å®Œæˆï¼Œè®°å½•å®Œæˆæ—¶é—´
                    if new_status in ['SUCCESS', 'FAILED']:
                        task.completed_at = datetime.utcnow()
                    
                    db.session.commit()
                    
                    update_log = TaskLog(
                        task_id=task_id,
                        message=f"ğŸ”„ ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°: {old_status} -> {new_status}"
                    )
                    db.session.add(update_log)
                    db.session.commit()
                    
                    logger.info(f"Task {task_id} status updated from {old_status} to {new_status}")
                    
                    # å¦‚æœä»»åŠ¡å®Œæˆï¼Œå°è¯•å¯åŠ¨é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªä»»åŠ¡
                    if new_status in ['SUCCESS', 'FAILED']:
                        complete_log = TaskLog(
                            task_id=task_id,
                            message=f"ğŸ ä»»åŠ¡å·²å®Œæˆï¼Œè§¦å‘é˜Ÿåˆ—å¤„ç†"
                        )
                        db.session.add(complete_log)
                        db.session.commit()
                        
                        # å¦‚æœä»»åŠ¡æˆåŠŸå®Œæˆï¼Œè‡ªåŠ¨è·å–å¹¶ä¿å­˜è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
                        if new_status == 'SUCCESS':
                            self._auto_fetch_task_outputs(task_id)
                        
                        # ä»»åŠ¡å®Œæˆåï¼Œé€šè¿‡ä¸­å¤®ç®¡ç†å™¨è§¦å‘é˜Ÿåˆ—å¤„ç†
                        central_queue_manager.request_queue_processing(
                            trigger_source=TriggerSource.TASK_COMPLETE,
                            reason=f"Task {task_id} completed with status {new_status}",
                            task_id=task_id
                        )
                else:
                    no_change_log = TaskLog(
                        task_id=task_id,
                        message=f"â„¹ï¸ çŠ¶æ€æ— å˜åŒ–ï¼Œä¿æŒ: {old_status}"
                    )
                    db.session.add(no_change_log)
                    db.session.commit()
                
                return True
            else:
                error_log = TaskLog(
                    task_id=task_id,
                    message="âŒ æœªèƒ½è·å–åˆ°æœ‰æ•ˆçš„çŠ¶æ€ä¿¡æ¯"
                )
                db.session.add(error_log)
                db.session.commit()
            
        except Exception as e:
            exception_log = TaskLog(
                task_id=task_id,
                message=f"âŒ æ›´æ–°ä»»åŠ¡çŠ¶æ€æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
            )
            db.session.add(exception_log)
            db.session.commit()
            logger.error(f"Error updating task status for {task_id}: {e}")
        
        return False
    
    def map_runninghub_status(self, runninghub_status):
        """å°†RunningHubçŠ¶æ€æ˜ å°„åˆ°æœ¬åœ°çŠ¶æ€"""
        status_mapping = {
            'queue': 'QUEUED',
            'queued': 'QUEUED',
            'running': 'RUNNING',
            'success': 'SUCCESS',
            'failed': 'FAILED',
            'error': 'FAILED',
            'cancelled': 'STOPPED',
            'canceled': 'STOPPED'
        }
        
        return status_mapping.get(runninghub_status.lower(), None)
    
    def update_all_running_tasks(self):
        """æ›´æ–°æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡çŠ¶æ€"""
        running_tasks = Task.query.filter(
            Task.status.in_(['QUEUED', 'RUNNING']),
            Task.runninghub_task_id.isnot(None)
        ).all()
        
        updated_count = 0
        for task in running_tasks:
            if self.update_task_status(task.task_id):
                updated_count += 1
        
        logger.debug(f"Updated {updated_count} running tasks")
        return updated_count
    
    def get_task_details(self, task_id):
        """è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯"""
        task = Task.query.get(task_id)
        if not task:
            return None
        
        result = task.to_dict()
        
        # æ·»åŠ å·¥ä½œæµä¿¡æ¯
        if hasattr(task, 'workflow') and task.workflow:
            result['workflow_name'] = task.workflow.name
            result['node_count'] = len(task.workflow.nodes)
        
        # æ·»åŠ ä»»åŠ¡æ•°æ®
        result['data'] = [data.to_dict() for data in task.data]
        
        # å¦‚æœæœ‰RunningHubä»»åŠ¡IDï¼Œè·å–è¯¦ç»†çŠ¶æ€
        if task.runninghub_task_id:
            try:
                runninghub_info = self.runninghub_service.get_task_status(task.runninghub_task_id)
                if runninghub_info:
                    result['runninghub_info'] = runninghub_info
            except Exception as e:
                logger.warning(f"Failed to get RunningHub info for task {task_id}: {e}")
        
        return result
    
    def start_monitoring(self):
        """å¯åŠ¨çŠ¶æ€ç›‘æ§"""
        if self.is_monitoring:
            logger.warning("Task monitoring is already running")
            return
        
        if not self.app:
            logger.error("Cannot start monitoring: app instance not set")
            return
        
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        logger.info("Task status monitoring started")
    
    def stop_monitoring(self):
        """åœæ­¢çŠ¶æ€ç›‘æ§"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("Task status monitoring stopped")
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                if self.app:
                    with self.app.app_context():
                        # æ›´æ–°æ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡çŠ¶æ€
                        self.update_all_running_tasks()
                        
                        # æ£€æŸ¥è¶…æ—¶ä»»åŠ¡ - ä½†ä¸è‡ªåŠ¨è§¦å‘é˜Ÿåˆ—å¤„ç†
                        from app.services.task_queue_service import TaskQueueService
                        queue_service = TaskQueueService()
                        timeout_count = queue_service.check_timeout_tasks_without_queue_processing()
                        
                        if timeout_count > 0:
                            logger.warning(f"Found {timeout_count} timeout tasks, processing queue...")
                            # åªæœ‰åœ¨å®é™…å¤„ç†äº†è¶…æ—¶ä»»åŠ¡æ—¶æ‰é€šè¿‡ä¸­å¤®ç®¡ç†å™¨è§¦å‘é˜Ÿåˆ—å¤„ç†
                            central_queue_manager.request_queue_processing(
                                trigger_source=TriggerSource.STATUS_MONITOR,
                                reason=f"Found {timeout_count} timeout tasks"
                            )
                        
                        # æ£€æŸ¥å¹¶å¤„ç†PENDINGçŠ¶æ€çš„ä»»åŠ¡
                        self._process_pending_tasks(queue_service)
                        
                        # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                        time.sleep(self.app.config.get('STATUS_CHECK_INTERVAL', 10))
                else:
                    # å¦‚æœæ²¡æœ‰åº”ç”¨å®ä¾‹ï¼Œä½¿ç”¨é»˜è®¤é—´éš”
                    time.sleep(10)
                
            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                time.sleep(5)  # å‡ºé”™æ—¶çŸ­æš‚ç­‰å¾…
    
    def get_task_progress(self, task_id):
        """è·å–ä»»åŠ¡è¿›åº¦ä¿¡æ¯"""
        task = Task.query.get(task_id)
        if not task or not task.runninghub_task_id:
            return None
        
        try:
            progress_info = self.runninghub_service.get_task_progress(task.runninghub_task_id)
            return progress_info
        except Exception as e:
            logger.error(f"Error getting task progress for {task_id}: {e}")
            return None
    
    def _process_pending_tasks(self, queue_service):
        """å¤„ç†PENDINGçŠ¶æ€çš„ä»»åŠ¡ - åªæœ‰å½“RunningHubä»»åŠ¡æ•°ä¸º0æ—¶æ‰å¤„ç†é˜Ÿåˆ—"""
        try:
            # æŸ¥è¯¢æ‰€æœ‰PENDINGçŠ¶æ€çš„ä»»åŠ¡
            pending_tasks = Task.query.filter_by(status='PENDING').order_by(Task.created_at.asc()).all()
            
            if pending_tasks:
                # æ£€æŸ¥RunningHubä¸­æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
                current_tasks = self.runninghub_service.check_account_status()
                
                if current_tasks is None:
                    # æ— æ³•è·å–RunningHubçŠ¶æ€æ—¶ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®åº“æ£€æŸ¥
                    running_count = Task.query.filter(Task.status.in_(['QUEUED', 'RUNNING'])).count()
                    can_process = running_count == 0
                else:
                    # åªæœ‰å½“RunningHubä¸­æ²¡æœ‰ä»»åŠ¡æ—¶æ‰å¤„ç†é˜Ÿåˆ—
                    can_process = current_tasks == 0
                
                if can_process:
                    logger.info(f"Found {len(pending_tasks)} pending tasks and RunningHub is idle, processing queue...")
                    # é€šè¿‡ä¸­å¤®ç®¡ç†å™¨è§¦å‘é˜Ÿåˆ—å¤„ç†
                    central_queue_manager.request_queue_processing(
                        trigger_source=TriggerSource.PENDING_CHECK,
                        reason="RunningHub is idle, processing pending tasks"
                    )
                else:
                    logger.debug(f"Found {len(pending_tasks)} pending tasks but RunningHub has {current_tasks} running tasks, waiting...")
        except Exception as e:
            logger.error(f"Error processing pending tasks: {e}")
    
    def get_task_outputs(self, task_id):
        """è·å–ä»»åŠ¡è¾“å‡ºæ–‡ä»¶"""
        try:
            # ä½¿ç”¨FileManagerçš„fallbackæ–¹æ³•
            from app.services.file_manager import FileManager
            file_manager = FileManager()
            outputs = file_manager.get_task_outputs_with_fallback(task_id)
            return outputs
        except Exception as e:
            logger.error(f"Error getting task outputs for {task_id}: {e}")
            return []
    
    def download_task_output(self, task_id, output_name):
        """ä¸‹è½½ä»»åŠ¡è¾“å‡ºæ–‡ä»¶"""
        task = Task.query.get(task_id)
        if not task or not task.runninghub_task_id:
            return None
        
        try:
            file_data = self.runninghub_service.download_output_file(task.runninghub_task_id, output_name)
            return file_data
        except Exception as e:
            logger.error(f"Error downloading task output {output_name} for {task_id}: {e}")
            return None
    
    def _auto_fetch_task_outputs(self, task_id):
        """ä»»åŠ¡å®Œæˆæ—¶è‡ªåŠ¨è·å–å¹¶ä¿å­˜è¾“å‡ºæ–‡ä»¶ä¿¡æ¯åˆ°TaskOutputè¡¨"""
        try:
            task = Task.query.get(task_id)
            if not task or not task.runninghub_task_id:
                logger.warning(f"Task {task_id} not found or missing runninghub_task_id")
                return
            
            # è·å–ä»»åŠ¡è¾“å‡ºæ–‡ä»¶
            outputs = self.runninghub_service.get_outputs(task.runninghub_task_id, task_id)
            
            if not outputs:
                logger.info(f"No outputs found for task {task_id}")
                return
            
            # åˆ›å»ºTaskOutputè®°å½•
            from app.models.TaskOutput import TaskOutput
            from app.utils.timezone_helper import now_utc
            from sqlalchemy.exc import IntegrityError
            import os
            
            created_count = 0
            skipped_count = 0
            
            for output in outputs:
                try:
                    # æå–æ–‡ä»¶ä¿¡æ¯
                    node_id = output.get('nodeId', '')
                    file_url = output.get('fileUrl', '')
                    file_type = output.get('fileType', '')
                    file_size = output.get('fileSize', 0)
                    
                    if not file_url:
                        continue
                    
                    # ä»URLä¸­æå–æ–‡ä»¶å
                    file_name = os.path.basename(file_url.split('?')[0])
                    
                    # åˆ›å»ºTaskOutputè®°å½•
                    task_output = TaskOutput(
                        task_id=task_id,
                        node_id=node_id,
                        name=file_name,
                        file_type=file_type,
                        file_size=file_size,
                        file_url=file_url,
                        thumbnail_path=None,
                        created_at=now_utc()
                    )
                    
                    db.session.add(task_output)
                    db.session.flush()  # æ£€æŸ¥çº¦æŸå†²çª
                    created_count += 1
                    
                    logger.info(f"Created TaskOutput record for task {task_id}, node {node_id}: {file_name}")
                    
                except IntegrityError:
                    # è®°å½•å·²å­˜åœ¨ï¼Œè·³è¿‡
                    db.session.rollback()
                    skipped_count += 1
                    logger.debug(f"TaskOutput record already exists for task {task_id}, node {node_id}")
                    continue
                except Exception as e:
                    logger.error(f"Error creating TaskOutput record for task {task_id}: {e}")
                    continue
            
            # æäº¤äº‹åŠ¡
            if created_count > 0:
                db.session.commit()
                
                # è®°å½•æˆåŠŸæ—¥å¿—
                success_log = TaskLog(
                    task_id=task_id,
                    message=f"âœ… è‡ªåŠ¨è·å–è¾“å‡ºæ–‡ä»¶å®Œæˆï¼šæ–°å»º{created_count}ä¸ªè®°å½•ï¼Œè·³è¿‡{skipped_count}ä¸ª"
                )
                db.session.add(success_log)
                db.session.commit()
                
                logger.info(f"Auto-fetched outputs for task {task_id}: created {created_count}, skipped {skipped_count}")
            else:
                db.session.rollback()
                logger.info(f"No new TaskOutput records created for task {task_id}")
                
        except Exception as e:
            try:
                db.session.rollback()
            except:
                pass
            
            # è®°å½•é”™è¯¯æ—¥å¿—
            error_log = TaskLog(
                task_id=task_id,
                message=f"âŒ è‡ªåŠ¨è·å–è¾“å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}"
            )
            db.session.add(error_log)
            db.session.commit()
            
            logger.error(f"Error auto-fetching outputs for task {task_id}: {e}")