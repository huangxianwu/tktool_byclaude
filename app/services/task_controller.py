"""
ä»»åŠ¡æ§åˆ¶å™¨
ç»Ÿä¸€ç®¡ç†ä»»åŠ¡çš„ç”Ÿå‘½å‘¨æœŸå’Œæ“ä½œ
"""
from flask import current_app
from app import db
from app.models.Task import Task
from app.services.task_queue_service import TaskQueueService
from app.services.task_status_service import TaskStatusService
import logging
import json

logger = logging.getLogger(__name__)

class TaskController:
    def __init__(self):
        self.queue_service = TaskQueueService()
        self.status_service = TaskStatusService()
    
    def get_tasks_with_workflow_info(self, status=None, workflow_id=None, start_date=None, end_date=None, search=None, sort_by='created_at', sort_order='desc'):
        """è·å–ä»»åŠ¡åˆ—è¡¨åŠå·¥ä½œæµä¿¡æ¯ï¼ˆæ”¯æŒç­›é€‰ï¼‰"""
        try:
            from datetime import datetime
            from sqlalchemy import or_, and_
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = Task.query
            
            # çŠ¶æ€ç­›é€‰
            if status:
                query = query.filter(Task.status == status.upper())
            
            # å·¥ä½œæµç­›é€‰
            if workflow_id:
                query = query.filter(Task.workflow_id == workflow_id)
            
            # æ—¶é—´èŒƒå›´ç­›é€‰
            if start_date:
                try:
                    # æ”¯æŒæ—¥æœŸæ ¼å¼ YYYY-MM-DD
                    if len(start_date) == 10:  # YYYY-MM-DD format
                        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
                    else:
                        start_dt = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
                    query = query.filter(Task.created_at >= start_dt)
                except (ValueError, TypeError):
                    pass
            
            if end_date:
                try:
                    # æ”¯æŒæ—¥æœŸæ ¼å¼ YYYY-MM-DDï¼Œè®¾ç½®ä¸ºå½“å¤©ç»“æŸæ—¶é—´
                    if len(end_date) == 10:  # YYYY-MM-DD format
                        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
                        # è®¾ç½®ä¸ºå½“å¤©çš„23:59:59
                        end_dt = end_dt.replace(hour=23, minute=59, second=59, microsecond=999999)
                    else:
                        end_dt = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
                    query = query.filter(Task.created_at <= end_dt)
                except (ValueError, TypeError):
                    pass
            
            # ä»»åŠ¡æè¿°æœç´¢
            if search:
                query = query.filter(or_(
                    Task.task_description.ilike(f'%{search}%'),
                    Task.task_id.ilike(f'%{search}%')
                ))
            
            # æ’åº
            if sort_by == 'created_at':
                if sort_order == 'desc':
                    query = query.order_by(Task.created_at.desc())
                else:
                    query = query.order_by(Task.created_at.asc())
            elif sort_by == 'status':
                if sort_order == 'desc':
                    query = query.order_by(Task.status.desc())
                else:
                    query = query.order_by(Task.status.asc())
            elif sort_by == 'task_id':
                if sort_order == 'desc':
                    query = query.order_by(Task.task_id.desc())
                else:
                    query = query.order_by(Task.task_id.asc())
            elif sort_by == 'workflow_id':
                if sort_order == 'desc':
                    query = query.order_by(Task.workflow_id.desc())
                else:
                    query = query.order_by(Task.workflow_id.asc())
            else:
                # é»˜è®¤æŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åº
                query = query.order_by(Task.created_at.desc())
            
            tasks = query.all()
            result = []
            
            for task in tasks:
                task_dict = task.to_dict()
                # å¤„ç†is_pluså­—æ®µå…¼å®¹æ€§
                if not hasattr(task, 'is_plus'):
                    task_dict['is_plus'] = False
                # å°è¯•æ·»åŠ å·¥ä½œæµä¿¡æ¯
                try:
                    if hasattr(task, 'workflow') and task.workflow:
                        task_dict['workflow_name'] = task.workflow.name
                        task_dict['node_count'] = len(task.workflow.nodes)
                    else:
                        # æ‰‹åŠ¨æŸ¥è¯¢å·¥ä½œæµä¿¡æ¯
                        from app.models.Workflow import Workflow
                        workflow = Workflow.query.get(task.workflow_id)
                        if workflow:
                            task_dict['workflow_name'] = workflow.name
                            task_dict['node_count'] = len(workflow.nodes)
                        else:
                            task_dict['workflow_name'] = 'Unknown'
                            task_dict['node_count'] = 0
                except Exception as e:
                    # å¦‚æœå·¥ä½œæµä¿¡æ¯è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    task_dict['workflow_name'] = 'Unknown'
                    task_dict['node_count'] = 0
                
                result.append(task_dict)
            
            return result
        except Exception as e:
            # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            logger.error(f"Error fetching tasks: {e}")
            return []
    
    def start_single_task(self, task_id):
        """å¯åŠ¨å•ä¸ªä»»åŠ¡"""
        logger.info(f"Starting task: {task_id}")
        return self.queue_service.start_task(task_id)
    
    def stop_single_task(self, task_id):
        """åœæ­¢å•ä¸ªä»»åŠ¡"""
        logger.info(f"Stopping task: {task_id}")
        return self.queue_service.stop_task(task_id)
    
    def delete_single_task(self, task_id):
        """åˆ é™¤å•ä¸ªä»»åŠ¡"""
        logger.info(f"Deleting task: {task_id}")
        
        task = Task.query.get(task_id)
        if not task:
            return False, "ä»»åŠ¡ä¸å­˜åœ¨"
        
        try:
            # å¦‚æœä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢å®ƒ
            if task.status in ['PENDING', 'QUEUED', 'RUNNING']:
                self.queue_service.stop_task(task_id)
            
            # åˆ é™¤ä»»åŠ¡
            db.session.delete(task)
            db.session.commit()
            
            logger.info(f"Task {task_id} deleted successfully")
            return True, "ä»»åŠ¡åˆ é™¤æˆåŠŸ"
            
        except Exception as e:
            logger.error(f"Error deleting task {task_id}: {e}")
            db.session.rollback()
            return False, f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}"
    
    def batch_start_tasks(self, task_ids):
        """æ‰¹é‡å¯åŠ¨ä»»åŠ¡"""
        logger.info(f"Batch starting tasks: {task_ids}")
        
        # éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½å¯ä»¥å¯åŠ¨
        invalid_tasks = []
        for task_id in task_ids:
            task = Task.query.get(task_id)
            if not task:
                invalid_tasks.append(f"{task_id}: ä»»åŠ¡ä¸å­˜åœ¨")
            elif task.status not in ['READY', 'FAILED', 'STOPPED']:
                invalid_tasks.append(f"{task_id}: çŠ¶æ€ {task.status} ä¸å…è®¸å¯åŠ¨")
        
        if invalid_tasks:
            return False, f"ä»¥ä¸‹ä»»åŠ¡æ— æ³•å¯åŠ¨: {'; '.join(invalid_tasks)}"
        
        # æ‰§è¡Œæ‰¹é‡å¯åŠ¨
        results = self.queue_service.batch_start_tasks(task_ids)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r['success'])
        total_count = len(results)
        
        if success_count == total_count:
            return True, f"æˆåŠŸå¯åŠ¨ {success_count} ä¸ªä»»åŠ¡"
        else:
            failed_tasks = [r['task_id'] for r in results if not r['success']]
            return False, f"å¯åŠ¨äº† {success_count}/{total_count} ä¸ªä»»åŠ¡ï¼Œå¤±è´¥çš„ä»»åŠ¡: {', '.join(failed_tasks)}"
    
    def batch_stop_tasks(self, task_ids):
        """æ‰¹é‡åœæ­¢ä»»åŠ¡"""
        logger.info(f"Batch stopping tasks: {task_ids}")
        
        # éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½å¯ä»¥åœæ­¢
        invalid_tasks = []
        for task_id in task_ids:
            task = Task.query.get(task_id)
            if not task:
                invalid_tasks.append(f"{task_id}: ä»»åŠ¡ä¸å­˜åœ¨")
            elif task.status not in ['PENDING', 'QUEUED', 'RUNNING']:
                invalid_tasks.append(f"{task_id}: çŠ¶æ€ {task.status} ä¸å…è®¸åœæ­¢")
        
        if invalid_tasks:
            return False, f"ä»¥ä¸‹ä»»åŠ¡æ— æ³•åœæ­¢: {'; '.join(invalid_tasks)}"
        
        # æ‰§è¡Œæ‰¹é‡åœæ­¢
        results = self.queue_service.batch_stop_tasks(task_ids)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r['success'])
        total_count = len(results)
        
        if success_count == total_count:
            return True, f"æˆåŠŸåœæ­¢ {success_count} ä¸ªä»»åŠ¡"
        else:
            failed_tasks = [r['task_id'] for r in results if not r['success']]
            return False, f"åœæ­¢äº† {success_count}/{total_count} ä¸ªä»»åŠ¡ï¼Œå¤±è´¥çš„ä»»åŠ¡: {', '.join(failed_tasks)}"
    
    def batch_delete_tasks(self, task_ids):
        """æ‰¹é‡åˆ é™¤ä»»åŠ¡"""
        logger.info(f"Batch deleting tasks: {task_ids}")
        
        success_count = 0
        failed_tasks = []
        
        for task_id in task_ids:
            success, message = self.delete_single_task(task_id)
            if success:
                success_count += 1
            else:
                failed_tasks.append(f"{task_id}: {message}")
        
        total_count = len(task_ids)
        
        if success_count == total_count:
            return True, f"æˆåŠŸåˆ é™¤ {success_count} ä¸ªä»»åŠ¡"
        else:
            return False, f"åˆ é™¤äº† {success_count}/{total_count} ä¸ªä»»åŠ¡ï¼Œå¤±è´¥çš„ä»»åŠ¡: {'; '.join(failed_tasks)}"
    
    def get_task_details(self, task_id):
        """è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯"""
        return self.status_service.get_task_details(task_id)
    
    def get_queue_status(self):
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        return self.queue_service.get_queue_status()
    
    def update_task_status(self, task_id):
        """æ‰‹åŠ¨æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        return self.status_service.update_task_status(task_id)
    
    def get_task_progress(self, task_id):
        """è·å–ä»»åŠ¡è¿›åº¦"""
        return self.status_service.get_task_progress(task_id)
    
    def get_task_outputs(self, task_id):
        """è·å–ä»»åŠ¡è¾“å‡º"""
        return self.status_service.get_task_outputs(task_id)
    
    def download_task_output(self, task_id, output_name):
        """ä¸‹è½½ä»»åŠ¡è¾“å‡ºæ–‡ä»¶"""
        return self.status_service.download_task_output(task_id, output_name)
    
    def download_task_files(self, task_id):
        """ä¸‹è½½ä»»åŠ¡çš„æ‰€æœ‰è¾“å‡ºæ–‡ä»¶åˆ°æœ¬åœ°"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºè¿œç¨‹æ¨¡å¼
        remote_only_mode = current_app.config.get('REMOTE_ONLY_MODE', False)
        if remote_only_mode:
            return {'success': False, 'error': 'File download is disabled in remote-only mode'}
        
        from app.services.file_manager import FileManager
        from app.services.runninghub import RunningHubService
        from app.models.Task import Task
        
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = Task.query.get(task_id)
        if not task:
            return {'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}
        
        if not task.runninghub_task_id:
            return {'success': False, 'error': 'ä»»åŠ¡æ²¡æœ‰è¿œç¨‹IDï¼Œæ— æ³•ä¸‹è½½æ–‡ä»¶'}
        
        try:
            # ä»RunningHubè·å–è¾“å‡ºæ–‡ä»¶
            runninghub_service = RunningHubService()
            outputs = runninghub_service.get_outputs(task.runninghub_task_id, task_id)
            
            if not outputs:
                return {'success': False, 'error': 'æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶'}
            
            # ä¸‹è½½å¹¶ä¿å­˜æ–‡ä»¶
            file_manager = FileManager()
            saved_files = file_manager.download_and_save_outputs(task_id, outputs)
            
            return {
                'success': True,
                'message': f'æˆåŠŸä¸‹è½½ {len(saved_files)} ä¸ªæ–‡ä»¶',
                'files': saved_files,
                'total_count': len(saved_files)
            }
            
        except Exception as e:
            logger.error(f"ä¸‹è½½ä»»åŠ¡æ–‡ä»¶å¤±è´¥ {task_id}: {e}")
            return {'success': False, 'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'}
    
    def validate_batch_operation(self, task_ids, operation):
        """éªŒè¯æ‰¹é‡æ“ä½œçš„æœ‰æ•ˆæ€§"""
        if not task_ids:
            return False, "æœªé€‰æ‹©ä»»åŠ¡"
        
        tasks = Task.query.filter(Task.task_id.in_(task_ids)).all()
        
        if len(tasks) != len(task_ids):
            found_ids = [t.task_id for t in tasks]
            missing_ids = [tid for tid in task_ids if tid not in found_ids]
            return False, f"ä»¥ä¸‹ä»»åŠ¡ä¸å­˜åœ¨: {', '.join(missing_ids)}"
        
        # æ ¹æ®æ“ä½œç±»å‹éªŒè¯ä»»åŠ¡çŠ¶æ€
        if operation == 'start':
            invalid_tasks = [t.task_id for t in tasks if t.status not in ['READY', 'FAILED', 'STOPPED']]
            if invalid_tasks:
                return False, f"ä»¥ä¸‹ä»»åŠ¡çŠ¶æ€ä¸å…è®¸å¯åŠ¨: {', '.join(invalid_tasks)}"
        
        elif operation == 'stop':
            invalid_tasks = [t.task_id for t in tasks if t.status not in ['PENDING', 'QUEUED', 'RUNNING']]
            if invalid_tasks:
                return False, f"ä»¥ä¸‹ä»»åŠ¡çŠ¶æ€ä¸å…è®¸åœæ­¢: {', '.join(invalid_tasks)}"
        
        # deleteæ“ä½œå…è®¸ä»»ä½•çŠ¶æ€
        
        return True, "éªŒè¯é€šè¿‡"
    
    def get_task_statistics(self):
        """è·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        # æŒ‰çŠ¶æ€ç»Ÿè®¡ä»»åŠ¡æ•°é‡
        for status in ['READY', 'PENDING', 'QUEUED', 'RUNNING', 'SUCCESS', 'FAILED', 'STOPPED']:
            count = Task.query.filter_by(status=status).count()
            stats[status.lower()] = count
        
        # æ€»ä»»åŠ¡æ•°
        stats['total'] = Task.query.count()
        
        # é˜Ÿåˆ—çŠ¶æ€
        queue_status = self.get_queue_status()
        stats.update(queue_status)
        
        return stats
    
    def get_task_logs(self, task_id):
        """è·å–ä»»åŠ¡æ‰§è¡Œæ—¥å¿—"""
        try:
            from app.models.TaskLog import TaskLog
            logs = TaskLog.query.filter_by(task_id=task_id).order_by(TaskLog.timestamp.asc()).all()
            return [
                {
                    'id': log.id,
                    'message': log.message,
                    'timestamp': log.timestamp.isoformat() if log.timestamp else None
                } for log in logs
            ]
        except Exception as e:
            logger.error(f"Error fetching task logs for {task_id}: {e}")
            return []
    
    def get_task_logs_history(self, task_id):
        """è·å–ä»»åŠ¡å†å²æ—¥å¿—"""
        return self.get_task_logs(task_id)
    
    def diagnose_and_retry(self, task_id: str):
        """
        è¯Šæ–­ä»»åŠ¡å¤±è´¥åŸå› ï¼ˆåŒ…æ‹¬APIKEY_INVALID_NODE_INFOç­‰ï¼‰ï¼Œå¿…è¦æ—¶è‡ªåŠ¨ä¿®å¤å­—æ®µå¹¶é‡è¯•æäº¤åˆ°RunningHubã€‚
        è¿”å›å­—å…¸ï¼ŒåŒ…æ‹¬è¯Šæ–­ç»“è®ºã€æ˜¯å¦ä¿®å¤ã€é‡è¯•ç»“æœç­‰ã€‚
        """
        from app import db
        from app.models.Task import Task
        from app.models.TaskLog import TaskLog
        from app.models.TaskData import TaskData
        from app.models.Node import Node
        from app.services.error_handler import ErrorHandler, RetryHandler, ErrorCode

        task = Task.query.get(task_id)
        if not task:
            return {'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}

        # è®°å½•è¯Šæ–­å¼€å§‹
        start_log = TaskLog(task_id=task_id, message="ğŸ©º å¼€å§‹è¯Šæ–­ä»»åŠ¡å¤±è´¥åŸå› å¹¶å°è¯•ä¿®å¤")
        db.session.add(start_log)
        db.session.commit()

        # æå–æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
        logs = TaskLog.query.filter_by(task_id=task_id).order_by(TaskLog.timestamp.desc()).limit(50).all()
        last_error_msg = None
        for log in logs:
            msg_upper = (log.message or '').upper()
            if 'âŒ' in log.message or 'ERROR' in msg_upper or 'FAILED' in msg_upper:
                last_error_msg = log.message
                break

        diagnose = {}
        error_code = None
        if last_error_msg:
            error_code, _ = ErrorHandler.parse_error_from_message(last_error_msg)
            diagnose['last_error'] = last_error_msg
            diagnose['error_code'] = error_code.value if error_code else None
        else:
            diagnose['last_error'] = None

        # å½“æ£€æµ‹åˆ°èŠ‚ç‚¹ä¿¡æ¯é”™è¯¯æ—¶ï¼Œå°è¯•ä¿®å¤å­—æ®µå
        fixed_summary = None
        if error_code == ErrorCode.RUNNINGHUB_INVALID_NODE_INFO or (last_error_msg and 'APIKEY_INVALID_NODE_INFO' in last_error_msg.upper()):
            fixed_summary = self._fix_task_data_field_names(task)
            fix_log = TaskLog(task_id=task_id, message=f"ğŸ› ï¸ è‡ªåŠ¨ä¿®å¤å­—æ®µå: {json.dumps(fixed_summary, ensure_ascii=False)}")
            db.session.add(fix_log)
            db.session.commit()

        # å†³å®šæ˜¯å¦è¿›è¡Œé‡è¯•
        should_retry = True
        if error_code and not RetryHandler.is_retryable(error_code):
            # èŠ‚ç‚¹ä¿¡æ¯é”™è¯¯åœ¨ä¿®å¤åä»å…è®¸é‡è¯•
            if error_code != ErrorCode.RUNNINGHUB_INVALID_NODE_INFO and not fixed_summary:
                should_retry = False

        retry_result = None
        if should_retry:
            queue_service = TaskQueueService()
            try:
                success, runninghub_task_id, error_msg = queue_service.submit_task_to_runninghub(task)
                retry_result = {
                    'success': success,
                    'runninghub_task_id': runninghub_task_id,
                    'error_msg': error_msg
                }
                # å†™å…¥æ—¥å¿—
                if success:
                    db.session.add(TaskLog(task_id=task_id, message=f"ğŸ” é‡è¯•æäº¤æˆåŠŸ â†’ è¿œç¨‹ID: {runninghub_task_id}"))
                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€ç”±queue_serviceå¤„ç†ï¼Œè¿™é‡Œè¡¥å……ä¸€æ¬¡ä¿éšœ
                    task.status = 'QUEUED'
                    task.runninghub_task_id = runninghub_task_id
                    db.session.commit()
                else:
                    db.session.add(TaskLog(task_id=task_id, message=f"ğŸ” é‡è¯•æäº¤å¤±è´¥: {error_msg}"))
                    db.session.commit()
            except Exception as e:
                retry_result = {'success': False, 'error': str(e)}
                db.session.add(TaskLog(task_id=task_id, message=f"ğŸ” é‡è¯•æäº¤å¼‚å¸¸: {str(e)}"))
                db.session.commit()
        else:
            db.session.add(TaskLog(task_id=task_id, message="â›” å½“å‰é”™è¯¯ç±»å‹ä¸å¯é‡è¯•ï¼Œå·²ç»“æŸè¯Šæ–­"))
            db.session.commit()

        return {
            'success': True,
            'diagnose': diagnose,
            'fixed': fixed_summary is not None,
            'fixed_summary': fixed_summary,
            'retry_result': retry_result
        }

    def _fix_task_data_field_names(self, task):
        """
        æ ¹æ®å·¥ä½œæµä¸­çš„èŠ‚ç‚¹ç±»å‹ï¼Œä¿®æ­£TaskDataçš„field_nameï¼Œä½¿å…¶ç¬¦åˆRunningHubæ ‡å‡†ï¼š
        - image â†’ field_name: 'image'
        - video â†’ field_name: 'file'ï¼Œå¹¶ç¡®ä¿å­˜åœ¨ 'video-preview'ï¼ˆä¸ºç©ºï¼‰
        - text  â†’ field_name: 'text'
        - numberâ†’ field_name: 'number'
        - audio â†’ field_name: 'audio'
        è¿”å›ä¿®æ”¹æ‘˜è¦ã€‚
        """
        from app import db
        from app.models.TaskData import TaskData
        from app.models.Node import Node

        # æ„å»ºèŠ‚ç‚¹ç±»å‹æ˜ å°„
        nodes = Node.query.filter_by(workflow_id=task.workflow_id).all()
        node_type_map = {n.node_id: n.node_type for n in nodes}

        standard_fields = {
            'image': ['image'],
            'video': ['file', 'video-preview'],
            'text': ['text'],
            'number': ['number'],
            'audio': ['audio']
        }

        changes = []
        # ä¿®æ­£ç°æœ‰å­—æ®µå
        for d in task.data:
            node_type = node_type_map.get(d.node_id)
            if not node_type:
                continue
            allowed = standard_fields.get(node_type, [])
            if allowed and d.field_name not in allowed:
                old = d.field_name
                d.field_name = allowed[0]
                changes.append({'node_id': d.node_id, 'from': old, 'to': d.field_name})
        db.session.commit()

        # ä¸ºvideoèŠ‚ç‚¹è¡¥å……video-preview
        for node_id, node_type in node_type_map.items():
            if node_type == 'video':
                has_preview = any((d.node_id == node_id and d.field_name == 'video-preview') for d in task.data)
                if not has_preview:
                    db.session.add(TaskData(task_id=task.task_id, node_id=node_id, field_name='video-preview', field_value=''))
                    changes.append({'node_id': node_id, 'added': 'video-preview'})
        db.session.commit()

        return {'changes': changes, 'total_changes': len(changes)}

    def refresh_task_files(self, task_id):
        """åˆ·æ–°ä»»åŠ¡è¾“å‡ºæ–‡ä»¶"""
        try:
            from app.services.runninghub import RunningHubService
            from app.services.file_manager import FileManager
            
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
            task = Task.query.get(task_id)
            if not task:
                raise Exception(f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
            
            # åˆå§‹åŒ–æœåŠ¡
            runninghub_service = RunningHubService()
            file_manager = FileManager()
            
            # ä»RunningHubè·å–æœ€æ–°çš„è¾“å‡ºæ–‡ä»¶
            try:
                if not task.runninghub_task_id:
                    raise Exception(f"ä»»åŠ¡ {task_id} æ²¡æœ‰å…³è”çš„RunningHubä»»åŠ¡ID")
                    
                outputs = runninghub_service.get_task_outputs(task.runninghub_task_id)
                if not outputs:
                    logger.info(f"ä»»åŠ¡ {task_id} åœ¨RunningHubä¸­æ²¡æœ‰è¾“å‡ºæ–‡ä»¶")
                    return 0
                
                updated_count = 0
                
                # å¤„ç†æ¯ä¸ªè¾“å‡ºæ–‡ä»¶
                for output in outputs:
                    try:
                        # ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°
                        saved_output = file_manager.save_output_file(
                            task_id=task_id,
                            file_name=output.get('name', ''),
                            file_url=output.get('url', ''),
                            file_type=output.get('type', 'file')
                        )
                        
                        if saved_output:
                            updated_count += 1
                            logger.info(f"æˆåŠŸä¿å­˜æ–‡ä»¶: {output.get('name')}")
                        
                    except Exception as file_error:
                        logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {output.get('name')}: {file_error}")
                        continue
                
                logger.info(f"ä»»åŠ¡ {task_id} æ–‡ä»¶åˆ·æ–°å®Œæˆï¼Œæ›´æ–°äº† {updated_count} ä¸ªæ–‡ä»¶")
                return updated_count
                
            except Exception as hub_error:
                logger.error(f"ä»RunningHubè·å–è¾“å‡ºæ–‡ä»¶å¤±è´¥: {hub_error}")
                raise Exception(f"æ— æ³•ä»RunningHubè·å–è¾“å‡ºæ–‡ä»¶: {str(hub_error)}")
                
        except Exception as e:
            logger.error(f"åˆ·æ–°ä»»åŠ¡æ–‡ä»¶å¤±è´¥ {task_id}: {e}")
            raise e